{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2.5rem;color:purple;\">Artificial Intelligence II</h1>\n",
    "<h1 style=\"font-size:1.5rem;color:purple;\">Deep Learning for Natural Language Processing (NLP)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we develop a sentiment classifier using only **Logistic Regression** and only **TF-IDF** in Python on a given Twitter dataset.  \n",
    "The dataset consists of three files: *train_dataset.csv, val_dataset.csv, test_dataset.csv*.  \n",
    "Train and Val consists of three columns: **ID, Text, Label**, and Test consists of two columns: **ID, Text**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the given data (*test.csv* to use for training the model, *val.csv* to use for validation of training and *test.csv* to use for predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train dataset (to use for training)\n",
    "df_train = pd.read_csv('datasets/train_dataset.csv')\n",
    "\n",
    "# Read val dataset (to use for validation of training)\n",
    "df_val = pd.read_csv('datasets/val_dataset.csv')\n",
    "\n",
    "# Read test dataset (to use for predictions)\n",
    "df_test = pd.read_csv('datasets/test_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the train dataset (the other two datasets have a similar structure to this one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189385</td>\n",
       "      <td>@whoisralphie dude  I'm so bummed ur leaving!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58036</td>\n",
       "      <td>oh my god, a severed foot was foun in a wheely...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190139</td>\n",
       "      <td>I end up &amp;quot;dog dialing&amp;quot; sumtimes. Wha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99313</td>\n",
       "      <td>@_rachelx meeeee toooooo!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157825</td>\n",
       "      <td>I was hoping I could stay home and work today,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148383</th>\n",
       "      <td>99894</td>\n",
       "      <td>just love the jonas brothers  its tooo bad i w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148384</th>\n",
       "      <td>61015</td>\n",
       "      <td>another day gone by....time is moving so fast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148385</th>\n",
       "      <td>36598</td>\n",
       "      <td>fuck college, i'm just gonna marry rich. : fuc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148386</th>\n",
       "      <td>83799</td>\n",
       "      <td>ZOMGZ NEW SONG FTW.  remember that night. &amp;lt;3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148387</th>\n",
       "      <td>185558</td>\n",
       "      <td>http://twitpic.com/7mwrd - Arby's took down th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148388 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                               Text  Label\n",
       "0       189385      @whoisralphie dude  I'm so bummed ur leaving!      0\n",
       "1        58036  oh my god, a severed foot was foun in a wheely...      0\n",
       "2       190139  I end up &quot;dog dialing&quot; sumtimes. Wha...      1\n",
       "3        99313                         @_rachelx meeeee toooooo!       0\n",
       "4       157825  I was hoping I could stay home and work today,...      0\n",
       "...        ...                                                ...    ...\n",
       "148383   99894  just love the jonas brothers  its tooo bad i w...      0\n",
       "148384   61015  another day gone by....time is moving so fast...       0\n",
       "148385   36598  fuck college, i'm just gonna marry rich. : fuc...      1\n",
       "148386   83799    ZOMGZ NEW SONG FTW.  remember that night. &lt;3      1\n",
       "148387  185558  http://twitpic.com/7mwrd - Arby's took down th...      0\n",
       "\n",
       "[148388 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:1.5rem;color:purple;\">Data Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we clean the datasets. First remove duplicate values, then remove unwanted symbols/characters (e.g. URLs, @mentions, numbers/characters) and convert every letter to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate values \n",
    "df_train = df_train.drop_duplicates().reset_index(drop=True)\n",
    "df_val = df_val.drop_duplicates().reset_index(drop=True)\n",
    "df_test = df_test.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to clean a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    # Remove mentions/usernames\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove numbers and characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Clean only Text column\n",
    "df_train['Text'] = df_train['Text'].apply(clean_text)\n",
    "df_val['Text'] = df_val['Text'].apply(clean_text)\n",
    "df_test['Text'] = df_train['Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values\n",
    "df_train = df_train.replace(r'^\\s*$', pd.NA, regex=True).dropna()\n",
    "df_val = df_val.replace(r'^\\s*$', pd.NA, regex=True).dropna()\n",
    "df_test = df_test.replace(r'^\\s*$', pd.NA, regex=True).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take a look at the same dataset as above, but cleaned (the other two datasets are cleaned as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189385</td>\n",
       "      <td>dude  im so bummed ur leaving</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58036</td>\n",
       "      <td>oh my god a severed foot was foun in a wheely ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190139</td>\n",
       "      <td>i end up quotdog dialingquot sumtimes whats do...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99313</td>\n",
       "      <td>meeeee toooooo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157825</td>\n",
       "      <td>i was hoping i could stay home and work today ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148383</th>\n",
       "      <td>99894</td>\n",
       "      <td>just love the jonas brothers  its tooo bad i w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148384</th>\n",
       "      <td>61015</td>\n",
       "      <td>another day gone bytime is moving so fast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148385</th>\n",
       "      <td>36598</td>\n",
       "      <td>fuck college im just gonna marry rich  fuck co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148386</th>\n",
       "      <td>83799</td>\n",
       "      <td>zomgz new song ftw  remember that night lt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148387</th>\n",
       "      <td>185558</td>\n",
       "      <td>arbys took down their roastburger coupon    ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148050 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                               Text  Label\n",
       "0       189385                      dude  im so bummed ur leaving      0\n",
       "1        58036  oh my god a severed foot was foun in a wheely ...      0\n",
       "2       190139  i end up quotdog dialingquot sumtimes whats do...      1\n",
       "3        99313                                    meeeee toooooo       0\n",
       "4       157825  i was hoping i could stay home and work today ...      0\n",
       "...        ...                                                ...    ...\n",
       "148383   99894  just love the jonas brothers  its tooo bad i w...      0\n",
       "148384   61015         another day gone bytime is moving so fast       0\n",
       "148385   36598  fuck college im just gonna marry rich  fuck co...      1\n",
       "148386   83799         zomgz new song ftw  remember that night lt      1\n",
       "148387  185558    arbys took down their roastburger coupon    ...      0\n",
       "\n",
       "[148050 rows x 3 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stopwords (this action keeps only the necessary words from a text and helps to ease the training of the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/christina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load english stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to remove stopwords from a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stopwords from a text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "\n",
    "    words = text.split()  # Separate text into words\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]  # Remove stopwords\n",
    "    clean_text = ' '.join(filtered_words)  # Join separated words into a text\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stopwords from all three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Text'] = df_train['Text'].apply(remove_stopwords)\n",
    "df_val['Text'] = df_val['Text'].apply(remove_stopwords)\n",
    "df_test['Text'] = df_test['Text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows with NaN values (some rows may be empty after removing stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values\n",
    "df_train = df_train.replace(r'^\\s*$', pd.NA, regex=True).dropna()\n",
    "df_val = df_val.replace(r'^\\s*$', pd.NA, regex=True).dropna()\n",
    "df_test = df_test.replace(r'^\\s*$', pd.NA, regex=True).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set word lemmatizer (this action transform words into their base or root forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for lemmatization in a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for lemmatization in a text\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = text.split()  # Separate text into words\n",
    "    lemmatized_text = \" \".join([lemmatizer.lemmatize(word, pos=\"v\") for word in words])  # Lemmatize words\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatize every word in Text column of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Text'] = df_train['Text'].apply(lemmatize_text)\n",
    "df_val['Text'] = df_val['Text'].apply(lemmatize_text)\n",
    "df_test['Text'] = df_test['Text'].apply(lemmatize_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
